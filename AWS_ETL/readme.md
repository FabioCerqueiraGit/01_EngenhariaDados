# Pipeline de Logs com AWS Glue e Redshift ğŸš€

## ğŸ“Œ DescriÃ§Ã£o
Este projeto implementa um pipeline de ETL na AWS para processar logs de acessos web. O pipeline extrai, transforma e carrega (ETL) dados de logs armazenados no Amazon S3 para um cluster do Amazon Redshift, utilizando AWS Glue para processamento e transformaÃ§Ã£o dos dados.

## ğŸ—ï¸ Arquitetura
1. **Amazon S3**: Armazena os arquivos brutos de logs.
2. **AWS Glue**: Executa o job de ETL para processar e transformar os logs.
3. **Amazon Redshift**: Armazena os dados transformados para anÃ¡lises.
4. **AWS Lambda (Opcional)**: Pode ser usado para acionar o Glue quando novos logs forem adicionados ao S3.

## ğŸ› ï¸ Tecnologias Utilizadas
- AWS S3
- AWS Glue
- AWS Lambda (Opcional)
- Amazon Redshift
- AWS IAM

## ğŸ“‚ Estrutura do Projeto
```
aws-etl-project/
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ raw_logs/  # Logs brutos
â”‚   â”œâ”€â”€ processed_logs/  # Logs transformados
â”‚â”€â”€ scripts/
â”‚   â”œâ”€â”€ etl_glue.py  # Script do job AWS Glue
â”‚   â”œâ”€â”€ setup_aws.sh  # Script para criaÃ§Ã£o da infraestrutura
â”‚â”€â”€ README.md
```

## ğŸš€ Como Executar o Projeto
1. **Configurar a AWS CLI:**
   ```bash
   aws configure
   ```
2. **Executar o script de configuraÃ§Ã£o:**
   ```bash
   ./setup_aws.sh
   ```
3. **Executar o job do AWS Glue:**
   ```bash
   aws glue start-job-run --job-name etl-glue-job
   ```
4. **Validar os dados no Redshift**
   ```sql
   SELECT * FROM logs_processed LIMIT 10;
   ```

## ğŸ“Œ PrÃ³ximos Passos
- Implementar monitoramento com AWS CloudWatch.
- Criar alertas para falhas no pipeline.
- Otimizar queries no Redshift para melhor performance.

---
ğŸ“Œ **DÃºvidas ou sugestÃµes? Fique Ã  vontade para contribuir!** ğŸš€

